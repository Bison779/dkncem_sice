{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aff5d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import LSTM,Dense\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "import time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2752a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "sys.path.append('/home/jovyan/work/code/tutorial-documentation-master/code/research/data_And_DataHandlingFiles/')\n",
    "from load_data import load_data\n",
    "\n",
    "# setting parameters\n",
    "# Select either the 2D state (theta/omega), or the 2D images\n",
    "\n",
    "system = '2D-State'\n",
    "#system = 'image'\n",
    "#resolution = '32'\n",
    "resolution = '256'\n",
    "xmax = 3\n",
    "xmax_labels = 2\n",
    "#Training\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 10\n",
    "NUM_HISTORICAL_STEPS_input = 20\n",
    "NUM_HISTORICAL_STEPS_output = 1\n",
    "\n",
    "#data_folder = 'Pendulum/3D_stateData_amplitude_max-0_linearPendulum-500-steps'\n",
    "#data_folder = 'Pendulum/3D_stateData_amplitude_max-0_nonLinearPendulum'\n",
    "#data_folder = 'Pendulum/3D_stateData_amplitude_max-0.7_nonLinearPendulum-thirdOfSamples'\n",
    "\n",
    "# Soft-Pendulum\n",
    "#data_folder = 'Soft-pendulum/50_historicSteps_smoothedData'\n",
    "data_folder = 'soft-pendulum/50_timesteps_V2'\n",
    "\n",
    "data_directory = '/home/jovyan/work/code/tutorial-documentation-master/code/research/data_And_DataHandlingFiles/' + data_folder\n",
    "#data_directory = '/home/jovyan/data/data/' + data_folder\n",
    "\n",
    "[train_generator, valid_generator, test_generator] = load_data(system,\n",
    "                                                                input_start_index = 0,\n",
    "                                                                output_start_index = NUM_HISTORICAL_STEPS_input-1,\n",
    "                                                                NUM_HISTORICAL_STEPS_input=NUM_HISTORICAL_STEPS_input,\n",
    "                                                                NUM_HISTORICAL_STEPS_output=NUM_HISTORICAL_STEPS_output, \n",
    "                                                                directory=data_directory,\n",
    "                                                                BATCH_SIZE=BATCH_SIZE,\n",
    "                                                                resolution=resolution,\n",
    "                                                                xmax=xmax,\n",
    "                                                                xmax_labels=xmax_labels,train_states=False)\n",
    "\n",
    "\n",
    "input_shape = train_generator[0][0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62018ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_generator[0][0].shape)\n",
    "print(train_generator[0][1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a67636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM name\n",
    "import os\n",
    "name = '{}/LSTM_Model_epochs_{}_HistoricalSteps_{}'.format(data_folder,EPOCHS,NUM_HISTORICAL_STEPS_input)\n",
    "save_path = '/home/jovyan/work/code/tutorial-documentation-master/code/research/Models/Simple_LSTM/' + name\n",
    "os.makedirs(save_path,exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165640e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeHistory(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.times = []\n",
    "\n",
    "    def on_epoch_begin(self, batch, logs={}):\n",
    "        self.epoch_time_start = time.time()\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.times.append(time.time() - self.epoch_time_start)\n",
    "        \n",
    "time_callback = TimeHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefda384",
   "metadata": {},
   "outputs": [],
   "source": [
    "EVALUATION_INTERVAL = len(train_generator._indices) // BATCH_SIZE\n",
    "VALIDATION_STEPS = len(valid_generator._indices) // BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305b8bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model returning only one step prediction\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from keras.layers import Input,Reshape\n",
    "\n",
    "x_in = Input(input_shape)\n",
    "x = LSTM(NUM_HISTORICAL_STEPS_input, activation='relu', input_shape=input_shape)(x_in)# Removed return sequences so it just returns the next step\n",
    "x = Dense(NUM_HISTORICAL_STEPS_input, activation='relu')(x)\n",
    "x = Dense(xmax_labels)(x)\n",
    "x = Reshape(target_shape=(NUM_HISTORICAL_STEPS_output,xmax_labels))(x) # This just adds axis=1 to make it the right shape for the output\n",
    "model = Model(x_in, x)\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "27265109",
   "metadata": {
    "tags": []
   },
   "source": [
    "# model returning multi-step prediction\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(LSTM(NUM_HISTORICAL_STEPS_input, activation='relu', return_sequences=True, input_shape=input_shape))\n",
    "model.add(Dense(NUM_HISTORICAL_STEPS_input, activation='relu'))\n",
    "model.add(Dense(xmax_labels))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a324cb",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "history = model.fit(train_generator, epochs=EPOCHS, \n",
    "                validation_data=valid_generator,\n",
    "                validation_steps=VALIDATION_STEPS,\n",
    "                steps_per_epoch=EVALUATION_INTERVAL,\n",
    "                verbose=1,callbacks=[time_callback])\n",
    "model.save(save_path)\n",
    "pickle.dump( time_callback.times, open(save_path+'/times.pickle', \"wb\" ) )\n",
    "pickle.dump( history.history, open(save_path+'/history.pickle', \"wb\" ) )\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca64c88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#name = 'LSTM_Model_3-Layer_epochs_10'\n",
    "history = pickle.load( open(save_path+'/history.pickle'.format(system), \"rb\" ) )\n",
    "# training loss\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "plt.figure()\n",
    "plt.plot((history['loss']), 'r')\n",
    "\n",
    "plt.legend(['loss'])\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bb6114",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check details of LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864cc3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = load_model(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c97c52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = model2.predict(train_generator[0][0])\n",
    "fig = plt.figure()\n",
    "for i in range(len(train_generator[0][0])):\n",
    "    plt.plot(range(NUM_HISTORICAL_STEPS_input),train_generator[0][0][i,:,0],'-b',label='angle @ time t')\n",
    "    plt.plot(range(NUM_HISTORICAL_STEPS_input-len(train_generator[0][1][i])+1,NUM_HISTORICAL_STEPS_input+1),train_generator[0][1][i,:,0],'--r',label='angle @ time t+1')\n",
    "    plt.plot(range(NUM_HISTORICAL_STEPS_input-len(yhat[i])+1,NUM_HISTORICAL_STEPS_input+1),yhat[i,:,0],'.g',label='predicted angle @ time t+1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df1b71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "index =0\n",
    "X = yhat[index]\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "plt.plot(range(len(train_generator[0][0][index])),train_generator[0][0][index,:,0],label=r'$\\theta$')\n",
    "plt.plot(range(len(train_generator[0][0][index])),train_generator[0][0][index,:,1],label=r'$\\omega$')\n",
    "plt.plot(range(len(train_generator[0][0][index])),train_generator[0][0][index,:,2],label=r'control (u)')\n",
    "\n",
    "plt.plot(range(NUM_HISTORICAL_STEPS_input,NUM_HISTORICAL_STEPS_input+len(X)),X[:,0],'.g',label=r'$\\theta$')\n",
    "plt.plot(range(NUM_HISTORICAL_STEPS_input,NUM_HISTORICAL_STEPS_input+len(X)),X[:,1],'.g',label=r'$\\omega$')\n",
    "\n",
    "plt.xlabel('time')\n",
    "plt.title('Comparison: Original vs ' + name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
